## Lv5. 전처리

### 파이썬 텍스트 데이터 전처리

1. 클렌징

   분석에 방해되는 특수문자, 기호, html, .xml 태그 등의 노이즈데이터 제거, 대소문자 통합

   * 정규 표현식(Regular Expression) : 계속해서 등장하는 글자들을 규칙에 기반하여 한 번에 제거(ex. 기사의 게재시간 등)

2. 필터링 / STOPWORD 지정

   불필요한 단어나 분석에 큰 의미가 없는 단어를 STOPWORD로 설정 후 데이터에서 제거(등장빈도가 적은 단어, 조사 등)

   클렌징 작업의 일부라고도 볼 수 있음.

3. 토큰화(Tokenization)

   형태소 분석을 통해 문장을 형태소 단위의 토큰으로 분리한다.

   Dacon에는 선 클렌징 후 토큰화라고 나와있지만 대부분의 텍스트 전처리에서는 토큰화부터 진행하고 클렌징을 함

4. 정규화(Normalization)

   표현 방법이 다른 단어들을 통합시켜서 같은 단어로 만들어준다.

   * 어간 추출(Stemming) 

     먹다 => 먹/다 => 먹, 먹어서 => 먹/어서, 먹는데 => 먹/는데, normalization => normal

     * 어간(stem) : 단어의 의미를 담고 있는 단어의 핵심 부분.

     * 접사(affix) : 단어에 추가적인 의미를 주는 부분, 한국말에서는 어미(ending)

   * 표제어 추출(Lemmatization) : 더 정확하다.

     먹다, 먹어서, 먹는데 => 먹다, normalization => normalization

     * 표제어(Lemma) : 기본 사전형 단어

[출처](https://wikidocs.net/21694)

### 파이썬 특정 텍스트 제거

`.replace()` : 문자열.replace(old, new, [count])

`.isalpha()` : 문자열.isalpha(), 문자열이 알파벳, 한글 등 문자로만 이루어져있으면 True

`.isalnum()` : 문자열.isalnum(), 문자열이 문자와 숫자로만 이루어져있으면 True 

`.isdecimal()` : 문자열.isdecimal(), 문자열이 숫자로만 이루어져있으면 True

* 텍스트 데이터에서 '\\n' 문자열을 ' '로 변경

```python
train['data'] = train['data'].apply(lambda x : str(x).replace('\\n',' '))
# '데이터프레임'['컬럼'].apply(함수) : 해당 함수를 데이터프레임의 해당 컬럼에 적용시킴
```



### 파이썬 형태소 분석기(konlpy)

```
형태소
1. 언어 뜻을 가진 가장 작은 말의 단위. ‘이야기책’의 ‘이야기’, ‘책’ 따위이다.
2. 언어 문법적 또는 관계적인 뜻만을 나타내는 단어나 단어 성분. 
```

* Komoran(Korean Morphological Analyzer)

* kkma(꼬꼬마)

  좀 더 구체적으로 형태소에 따라 단어를 쪼갠다.

* okt(Open Korean Text processor)

  stem=True, norm = True의 파라미터가 존재해서, 단어들을 알아서 정규화 해주고, 오타도 수정해주는 기능을 가지고 있다.

`.pos(text)` : 텍스트를 형태소 단위로 쪼개서 품사 정보를 부착하여 반환한다. 

```python
from konlpy.tag import Okt
okt = Okt()
text = '마음에 꽂힌 칼한자루 보다 마음에 꽂힌 꽃한송이가 더 아파서 잠이 오지 않는다'
okt.pos(text,norm=True, stem=True)
=> [('마음', 'Noun'),
 ('에', 'Josa'),
 ('꽂히다', 'Verb'),
 ('칼', 'Noun'),
 ('한', 'Determiner'),
 ('자루', 'Noun'),
 ('보다', 'Verb'),
 ('마음', 'Noun'),
 ('에', 'Josa'),
 ('꽂히다', 'Verb'),
 ('꽃', 'Noun'),
 ('한송이', 'Noun'),
 ('가', 'Josa'),
 ('더', 'Noun'),
 ('아프다', 'Adjective'),
 ('잠', 'Noun'),
 ('이', 'Josa'),
 ('오지', 'Noun'),
 ('않다', 'Verb')]

okt.pos(text)
=> [('마음', 'Noun'),
 ('에', 'Josa'),
 ('꽂힌', 'Verb'),
 ('칼', 'Noun'),
 ('한', 'Determiner'),
 ('자루', 'Noun'),
 ('보다', 'Verb'),
 ('마음', 'Noun'),
 ('에', 'Josa'),
 ('꽂힌', 'Verb'),
 ('꽃', 'Noun'),
 ('한송이', 'Noun'),
 ('가', 'Josa'),
 ('더', 'Noun'),
 ('아파서', 'Adjective'),
 ('잠', 'Noun'),
 ('이', 'Josa'),
 ('오지', 'Noun'),
 ('않는다', 'Verb')]
```

`.nouns(text)` : 텍스트를 형태소 단위로 쪼개서 명사들만 반환한다.

```python
okt.nouns(text)
=> ['마음', '칼', '자루', '마음', '꽃', '한송이', '더', '잠', '오지']
```

`.morphs(text)` : 텍스트를 형태소 단위로 쪼개서 반환한다.

```python
okt.morphs(text, norm=True, stem=True)
=> ['마음', '에', '꽂히다', '칼', '한', '자루', '보다', '마음', '에', '꽂히다', '꽃', '한송이', '가', '더', '아프다', '잠', '이', '오지', '않다']
```



